{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structurer et explorer des données textuelles\n",
    "\n",
    "Notebook Introduction au traitement du langage naturel - 15/05/2025 - Émilien Schultz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les données\n",
    "\n",
    "Open Alex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les bibliothèques\n",
    "\n",
    "- `pandas` pour la manipulation de données\n",
    "- `nltk` pour le traitement de texte\n",
    "- `matplotlib` pour la visualisation\n",
    "- `scikit-learn` pour le traitement de texte et la modélisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas nltk scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer les données (préprocessing)\n",
    "\n",
    "- Supprimer les doublons\n",
    "- Supprimer les lignes vides\n",
    "- Convertir en minuscules\n",
    "- Garder uniquement de l'anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre éléments nuls:  759\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# charge les données\n",
    "df = pd.read_csv(\"../data/CSS_exact_openalex.csv\")\n",
    "\n",
    "# filtrer les éléments nuls\n",
    "print(\"Nombre éléments nuls: \", df[\"abstract\"].isna().sum())\n",
    "df = df[~df[\"abstract\"].isna()]\n",
    "\n",
    "# colonne avec tout le contenu textuel\n",
    "df[\"texte\"] = df[\"title\"] + \" \" + df[\"abstract\"]\n",
    "\n",
    "# ajouter un filtre sur la longueur des abstracts\n",
    "df = df[(df[\"texte\"].apply(len) < 10000) & (df[\"texte\"].apply(len) > 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Computational Social Science 14,0642,033Metric...\n",
       "1    Manifesto of computational social science The ...\n",
       "3    Computational Social Science and Sociology The...\n",
       "7    Can Large Language Models Transform Computatio...\n",
       "9    On agent-based modeling and computational soci...\n",
       "Name: texte, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"texte\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "683"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse à l'échelle des mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chercher la présence d'un mot\n",
    "\n",
    "Les bases de la fouille de données. Quels sont les questions qui parlent d'intelligence artificielle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(51)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtre = df[\"texte\"].str.contains(\"artificial intelligence|AI\")\n",
    "filtre.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[filtre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Serious Games and AI: Challenges and Opportunities for Computational Social Science The video game industry plays an essential role in the entertainment sphere of our society. However, from Monopoly to Flight Simulators, serious games have also been appealing tools for learning a new language, conveying values, or training skills. Furthermore, the resurgence of Artificial Intelligence (AI) and data science in the last decade has created a unique opportunity since the amount of data collected through a game is immense, as is the amount of data needed to feed such AI algorithms. This paper aims to identify relevant research lines using Serious Games as a novel research tool, especially in Computational Social Sciences. To contextualize, we also conduct a (non-systematic) literature review of this field. We conclude that the synergy between games and data can foster the use of AI for good and open up new strategies to empower humanity and support social research with novel computational tools. We also discuss the challenges and new opportunities that arise from aspiring to such lofty goals.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[filtre].loc[58, \"texte\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rechercher les nombres de 4 chiffres dans le texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2323']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(r\"\\s(\\d{4})\\s\",\"Ceci est un texte 2323 qds qsds dqs dsq 32 4444444\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chercher un contexte d'un mot avec une expression régulière"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rgence of Artificial Intelligence (AI) and ']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(\".{10}Artificial Intelligence.{10}\", df[filtre].loc[58, \"texte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(31)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"texte\"].str.lower()\n",
    "            .str.contains(\"artificial intelligence\")\n",
    "            .sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et si on cherche plusieurs termes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(46)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termes = [\" ai \", \"artificial intelligence\"]\n",
    "\n",
    "(df[\"texte\"].str.lower()\n",
    "            .str.contains(\"|\".join(termes))\n",
    "            .sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire une recherche sur toutes les variables possibles de l'IA\n",
    "\n",
    "- intelligence artificelle\n",
    "- algorithme\n",
    "- AI\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation\n",
    "\n",
    "Découper un texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utiliser les regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ceci', 'est', 'un', 'test', 'de', 'découpage', 'en', 'mots']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "word_pattern = r\"\\w+\"\n",
    "tokens = re.findall(word_pattern, \"Ceci est un test,de.découpage en mots\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.1 ms ± 461 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df[\"texte\"].apply(lambda x: re.findall(r\"\\w+\",x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utiliser une première bibliothèque : `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/emilien/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ceci', 'est', 'un', 'test', ',', 'ici-même']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize(\"Ceci est un test, ici-même\", language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_tokenize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347 ms ± 3.67 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df[\"texte\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"texte_tok\"] = df[\"texte\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quels sont les termes les plus fréquents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "compteur = Counter([j for i in list(df[\"texte_tok\"]) for j in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 6972),\n",
       " ('the', 5687),\n",
       " ('of', 5198),\n",
       " ('and', 5063),\n",
       " ('.', 4603),\n",
       " ('to', 3034),\n",
       " ('in', 2659),\n",
       " ('a', 2230),\n",
       " ('social', 1840),\n",
       " ('for', 1399),\n",
       " ('on', 1221),\n",
       " ('that', 1168),\n",
       " ('data', 1065),\n",
       " (')', 1058),\n",
       " ('(', 1038),\n",
       " ('is', 974),\n",
       " ('science', 895),\n",
       " ('computational', 872),\n",
       " ('with', 824),\n",
       " ('as', 815)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compteur.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelles sont les expressions qui reviennent le plus souvent ?\n",
    "\n",
    "Utilisons les bigrammes et les trigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Je', 'suis', 'content'),\n",
       " ('suis', 'content', 'de'),\n",
       " ('content', 'de', 'faire'),\n",
       " ('de', 'faire', 'du'),\n",
       " ('faire', 'du', 'Python')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "list(ngrams([\"Je\",\"suis\",\"content\",\"de\",\"faire\",\"du\",\"Python\"],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computational', 'social', 'science'),\n",
       " ('social', 'science', '14,0642,033metricstotal'),\n",
       " ('science', '14,0642,033metricstotal', 'downloads14,064last'),\n",
       " ('14,0642,033metricstotal', 'downloads14,064last', '6'),\n",
       " ('downloads14,064last', '6', 'months2,037last'),\n",
       " ('6', 'months2,037last', '12'),\n",
       " ('months2,037last', '12', 'months4,190total'),\n",
       " ('12', 'months4,190total', 'citations2,033last'),\n",
       " ('months4,190total', 'citations2,033last', '6'),\n",
       " ('citations2,033last', '6', 'months1last'),\n",
       " ('6', 'months1last', '12'),\n",
       " ('months1last', '12', 'months1view'),\n",
       " ('12', 'months1view', 'all'),\n",
       " ('months1view', 'all', 'metrics')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def generate_bigrams_nltk(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    bigrams = list(ngrams(tokens, 3))\n",
    "    return bigrams\n",
    "\n",
    "generate_bigrams_nltk(df[\"texte\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enlever les stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/emilien/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "#stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/emilien/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = list(set(stopwords.words(\"english\")))\n",
    "\n",
    "def generate_bigrams_nltk(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [token for token in tokens if token.isalnum() and token not in english_stopwords]\n",
    "    bigrams = list(ngrams(filtered_tokens, 2))\n",
    "    return bigrams\n",
    "\n",
    "def generate_trigrams_nltk(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [token for token in tokens if token.isalnum() and token not in english_stopwords]\n",
    "    bigrams = list(ngrams(filtered_tokens, 3))\n",
    "    return bigrams\n",
    "\n",
    "\n",
    "#generate_trigrams_nltk(df[\"texte\"].iloc[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computational social science     733\n",
       "computational social sciences     99\n",
       "social science research           57\n",
       "large language models             55\n",
       "natural language processing       54\n",
       "                                ... \n",
       "social welfare scholars            4\n",
       "source information societal        4\n",
       "csv keyword koronawirus            4\n",
       "stable calibration curve           4\n",
       "related social behavior            4\n",
       "Length: 300, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=english_stopwords, ngram_range=(3, 3), max_features=300)\n",
    "bigrammes = (\n",
    "    pd.DataFrame(\n",
    "        vectorizer.fit_transform(df[\"texte\"]).toarray(),\n",
    "        columns=vectorizer.get_feature_names_out(),\n",
    "    )\n",
    "    .T.sum(axis=1)\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "bigrammes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représenter les textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présence de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f9/d2d_05ws5gncmml0fx0c00kw0000gp/T/ipykernel_92286/1128864902.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table = df[[\"dim1\",\"dim2\",\"dim3\",\"dim4\"]].replace({True:1,False:0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dim1  dim2  dim3  dim4\n",
       "0        0     1     0     0\n",
       "1        0     1     0     0\n",
       "3        0     1     0     0\n",
       "7        0     1     0     1\n",
       "9        0     1     0     0\n",
       "...    ...   ...   ...   ...\n",
       "1427     0     1     0     0\n",
       "1429     0     1     0     1\n",
       "1430     0     1     0     1\n",
       "1436     0     1     0     0\n",
       "1439     0     1     0     0\n",
       "\n",
       "[683 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"texte\"] = df[\"texte\"].str.lower()\n",
    "df[\"dim1\"] = df[\"texte\"].str.contains(\"AI\")\n",
    "df[\"dim2\"] = df[\"texte\"].str.contains(\"science\")\n",
    "df[\"dim3\"] = df[\"texte\"].str.contains(\"algorithm\")\n",
    "df[\"dim4\"] = df[\"texte\"].str.contains(\"llm\")\n",
    "table = df[[\"dim1\",\"dim2\",\"dim3\",\"dim4\"]].replace({True:1,False:0})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table.sum(axis=1) > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parenthèse scikit-learn\n",
    "\n",
    "- on crée un objet/modèle par défaut avec des paramètres\n",
    "- on l'adapte aux données (fit) : on calcule les valeurs du modèle par rapport aux données\n",
    "- on prédit/transforme d'autres données (ou les mêmes) avec le modèle entrainé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vecteur brut : Document term matrix (DTM) / tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19</th>\n",
       "      <th>2020</th>\n",
       "      <th>ability</th>\n",
       "      <th>abstract</th>\n",
       "      <th>academic</th>\n",
       "      <th>access</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>across</th>\n",
       "      <th>active</th>\n",
       "      <th>...</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>workshop</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>www</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     19  2020  ability  abstract  academic  access  accounts  accuracy  \\\n",
       "0     0     0        0         0         0       0         0         0   \n",
       "1     0     0        1         0         0       0         0         0   \n",
       "2     0     0        0         0         0       0         0         0   \n",
       "3     0     0        0         1         0       0         0         0   \n",
       "4     0     0        0         0         0       0         0         0   \n",
       "..   ..   ...      ...       ...       ...     ...       ...       ...   \n",
       "678   0     0        0         1         0       0         0         0   \n",
       "679   0     0        1         0         0       0         0         0   \n",
       "680   0     0        0         0         0       0         0         0   \n",
       "681   0     0        0         0         0       0         0         0   \n",
       "682   0     0        0         0         0       0         0         0   \n",
       "\n",
       "     across  active  ...  word  words  work  working  workshop  world  would  \\\n",
       "0         0       0  ...     0      0     0        0         0      0      0   \n",
       "1         0       0  ...     0      0     1        0         0      0      0   \n",
       "2         0       0  ...     0      0     1        0         0      0      0   \n",
       "3         0       0  ...     0      0     1        0         0      0      0   \n",
       "4         0       0  ...     0      0     0        0         0      0      0   \n",
       "..      ...     ...  ...   ...    ...   ...      ...       ...    ...    ...   \n",
       "678       0       0  ...     0      0     0        0         0      0      0   \n",
       "679       0       0  ...     0      0     0        0         0      1      0   \n",
       "680       0       0  ...     0      0     0        0         0      1      0   \n",
       "681       0       0  ...     0      0     1        0         0      3      1   \n",
       "682       0       0  ...     0      0     3        0         1      0      0   \n",
       "\n",
       "     www  years  yet  \n",
       "0      0      0    0  \n",
       "1      0      0    0  \n",
       "2      0      0    0  \n",
       "3      0      0    0  \n",
       "4      0      0    0  \n",
       "..   ...    ...  ...  \n",
       "678    0      0    0  \n",
       "679    0      0    0  \n",
       "680    0      0    0  \n",
       "681    0      1    0  \n",
       "682    3      1    0  \n",
       "\n",
       "[683 rows x 500 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# créer mon object de ML\n",
    "vectorizer = CountVectorizer(stop_words=english_stopwords, \n",
    "                             ngram_range=(1, 1), \n",
    "                             max_features=500)\n",
    "\n",
    "# appliquer sur les données\n",
    "X = vectorizer.fit_transform(df[\"texte\"])\n",
    "X = pd.DataFrame(X.toarray(),columns=list(vectorizer.get_feature_names_out()))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Une version un peu plus avancée\n",
    "\n",
    "- Term Frequency-Inverse Document Frequency\n",
    "    - Amélioration du DTM\n",
    "- Approche souvent utilisée pour mettre en valeur les mots les plus spécifiques\n",
    "- `Scikit-learn` a `TfidfVectorizer`\n",
    "\n",
    "$$\\text{TF-IDF}(t, d, D) = \\left( \\frac{f_{t,d}}{n_d} \\right) \\times \\log \\left(\\frac{N}{\\text{df}_t} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19             0.000000\n",
       "popularity     0.000000\n",
       "popular        0.000000\n",
       "political      0.000000\n",
       "policy         0.000000\n",
       "                 ...   \n",
       "performance    0.211079\n",
       "tasks          0.216117\n",
       "nlp            0.253746\n",
       "strategies     0.343297\n",
       "data           0.421374\n",
       "Name: 45, Length: 500, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# créer un objet\n",
    "vectorizer = TfidfVectorizer(stop_words=english_stopwords, \n",
    "                             ngram_range=(1, 1), \n",
    "                             max_features=500)\n",
    "\n",
    "# applique \n",
    "X = vectorizer.fit_transform(df[\"texte\"])\n",
    "\n",
    "# mettre en forme\n",
    "X = pd.DataFrame(X.toarray(),columns=list(vectorizer.get_feature_names_out()))\n",
    "X.loc[45].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire la matrice TF-IDF, identifier les mots qui ont le score le plus important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance entre deux textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38885635]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "X = vectorizer.fit_transform(df[\"texte\"])\n",
    "cosine_similarity(X[0], X[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>673</th>\n",
       "      <th>674</th>\n",
       "      <th>675</th>\n",
       "      <th>676</th>\n",
       "      <th>677</th>\n",
       "      <th>678</th>\n",
       "      <th>679</th>\n",
       "      <th>680</th>\n",
       "      <th>681</th>\n",
       "      <th>682</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792856</td>\n",
       "      <td>0.683709</td>\n",
       "      <td>0.893938</td>\n",
       "      <td>0.862499</td>\n",
       "      <td>0.610080</td>\n",
       "      <td>0.882147</td>\n",
       "      <td>0.815532</td>\n",
       "      <td>0.841434</td>\n",
       "      <td>0.842699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.858356</td>\n",
       "      <td>0.981518</td>\n",
       "      <td>0.986131</td>\n",
       "      <td>0.957205</td>\n",
       "      <td>0.965213</td>\n",
       "      <td>0.974557</td>\n",
       "      <td>0.975362</td>\n",
       "      <td>0.959075</td>\n",
       "      <td>0.908659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.792856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792380</td>\n",
       "      <td>0.950557</td>\n",
       "      <td>0.906473</td>\n",
       "      <td>0.905994</td>\n",
       "      <td>0.870481</td>\n",
       "      <td>0.927642</td>\n",
       "      <td>0.841452</td>\n",
       "      <td>0.863517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866931</td>\n",
       "      <td>0.890152</td>\n",
       "      <td>0.938361</td>\n",
       "      <td>0.945397</td>\n",
       "      <td>0.918154</td>\n",
       "      <td>0.970727</td>\n",
       "      <td>0.965741</td>\n",
       "      <td>0.968236</td>\n",
       "      <td>0.880703</td>\n",
       "      <td>0.840238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683709</td>\n",
       "      <td>0.792380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941215</td>\n",
       "      <td>0.840601</td>\n",
       "      <td>0.599256</td>\n",
       "      <td>0.885338</td>\n",
       "      <td>0.871111</td>\n",
       "      <td>0.940411</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875743</td>\n",
       "      <td>0.806255</td>\n",
       "      <td>0.948565</td>\n",
       "      <td>0.970533</td>\n",
       "      <td>0.779773</td>\n",
       "      <td>0.969907</td>\n",
       "      <td>0.924779</td>\n",
       "      <td>0.933613</td>\n",
       "      <td>0.893843</td>\n",
       "      <td>0.864202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893938</td>\n",
       "      <td>0.950557</td>\n",
       "      <td>0.941215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848588</td>\n",
       "      <td>0.923259</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>0.943772</td>\n",
       "      <td>0.922710</td>\n",
       "      <td>0.954753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923321</td>\n",
       "      <td>0.956766</td>\n",
       "      <td>0.648462</td>\n",
       "      <td>0.975396</td>\n",
       "      <td>0.974159</td>\n",
       "      <td>0.989460</td>\n",
       "      <td>0.831055</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.946884</td>\n",
       "      <td>0.901888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.862499</td>\n",
       "      <td>0.906473</td>\n",
       "      <td>0.840601</td>\n",
       "      <td>0.848588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.858155</td>\n",
       "      <td>0.951050</td>\n",
       "      <td>0.942069</td>\n",
       "      <td>0.978197</td>\n",
       "      <td>0.955526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958900</td>\n",
       "      <td>0.896101</td>\n",
       "      <td>0.947750</td>\n",
       "      <td>0.982619</td>\n",
       "      <td>0.976048</td>\n",
       "      <td>0.988140</td>\n",
       "      <td>0.951046</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.935287</td>\n",
       "      <td>0.895721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.965213</td>\n",
       "      <td>0.970727</td>\n",
       "      <td>0.969907</td>\n",
       "      <td>0.989460</td>\n",
       "      <td>0.988140</td>\n",
       "      <td>0.976631</td>\n",
       "      <td>0.954114</td>\n",
       "      <td>0.978225</td>\n",
       "      <td>0.988795</td>\n",
       "      <td>0.983512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993712</td>\n",
       "      <td>0.969345</td>\n",
       "      <td>0.987226</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.993546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993665</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.992462</td>\n",
       "      <td>0.985277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0.974557</td>\n",
       "      <td>0.965741</td>\n",
       "      <td>0.924779</td>\n",
       "      <td>0.831055</td>\n",
       "      <td>0.951046</td>\n",
       "      <td>0.948494</td>\n",
       "      <td>0.957458</td>\n",
       "      <td>0.944670</td>\n",
       "      <td>0.992543</td>\n",
       "      <td>0.964447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968872</td>\n",
       "      <td>0.967898</td>\n",
       "      <td>0.857216</td>\n",
       "      <td>0.963013</td>\n",
       "      <td>0.975592</td>\n",
       "      <td>0.993665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.891661</td>\n",
       "      <td>0.950135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>0.975362</td>\n",
       "      <td>0.968236</td>\n",
       "      <td>0.933613</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.950489</td>\n",
       "      <td>0.962293</td>\n",
       "      <td>0.930484</td>\n",
       "      <td>0.992779</td>\n",
       "      <td>0.971529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969212</td>\n",
       "      <td>0.966520</td>\n",
       "      <td>0.847640</td>\n",
       "      <td>0.962830</td>\n",
       "      <td>0.972397</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.890135</td>\n",
       "      <td>0.945566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.959075</td>\n",
       "      <td>0.880703</td>\n",
       "      <td>0.893843</td>\n",
       "      <td>0.946884</td>\n",
       "      <td>0.935287</td>\n",
       "      <td>0.945041</td>\n",
       "      <td>0.932284</td>\n",
       "      <td>0.976206</td>\n",
       "      <td>0.977289</td>\n",
       "      <td>0.959670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903483</td>\n",
       "      <td>0.859381</td>\n",
       "      <td>0.849099</td>\n",
       "      <td>0.921980</td>\n",
       "      <td>0.641424</td>\n",
       "      <td>0.992462</td>\n",
       "      <td>0.891661</td>\n",
       "      <td>0.890135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.864907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0.908659</td>\n",
       "      <td>0.840238</td>\n",
       "      <td>0.864202</td>\n",
       "      <td>0.901888</td>\n",
       "      <td>0.895721</td>\n",
       "      <td>0.881019</td>\n",
       "      <td>0.885647</td>\n",
       "      <td>0.740696</td>\n",
       "      <td>0.886661</td>\n",
       "      <td>0.768130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599125</td>\n",
       "      <td>0.813462</td>\n",
       "      <td>0.886471</td>\n",
       "      <td>0.916943</td>\n",
       "      <td>0.742582</td>\n",
       "      <td>0.985277</td>\n",
       "      <td>0.950135</td>\n",
       "      <td>0.945566</td>\n",
       "      <td>0.864907</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.000000  0.792856  0.683709  0.893938  0.862499  0.610080  0.882147   \n",
       "1    0.792856  0.000000  0.792380  0.950557  0.906473  0.905994  0.870481   \n",
       "2    0.683709  0.792380  0.000000  0.941215  0.840601  0.599256  0.885338   \n",
       "3    0.893938  0.950557  0.941215  0.000000  0.848588  0.923259  0.936298   \n",
       "4    0.862499  0.906473  0.840601  0.848588  0.000000  0.858155  0.951050   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "678  0.965213  0.970727  0.969907  0.989460  0.988140  0.976631  0.954114   \n",
       "679  0.974557  0.965741  0.924779  0.831055  0.951046  0.948494  0.957458   \n",
       "680  0.975362  0.968236  0.933613  0.815939  0.950153  0.950489  0.962293   \n",
       "681  0.959075  0.880703  0.893843  0.946884  0.935287  0.945041  0.932284   \n",
       "682  0.908659  0.840238  0.864202  0.901888  0.895721  0.881019  0.885647   \n",
       "\n",
       "          7         8         9    ...       673       674       675  \\\n",
       "0    0.815532  0.841434  0.842699  ...  0.934959  0.858356  0.981518   \n",
       "1    0.927642  0.841452  0.863517  ...  0.866931  0.890152  0.938361   \n",
       "2    0.871111  0.940411  0.830467  ...  0.875743  0.806255  0.948565   \n",
       "3    0.943772  0.922710  0.954753  ...  0.923321  0.956766  0.648462   \n",
       "4    0.942069  0.978197  0.955526  ...  0.958900  0.896101  0.947750   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "678  0.978225  0.988795  0.983512  ...  0.993712  0.969345  0.987226   \n",
       "679  0.944670  0.992543  0.964447  ...  0.968872  0.967898  0.857216   \n",
       "680  0.930484  0.992779  0.971529  ...  0.969212  0.966520  0.847640   \n",
       "681  0.976206  0.977289  0.959670  ...  0.903483  0.859381  0.849099   \n",
       "682  0.740696  0.886661  0.768130  ...  0.599125  0.813462  0.886471   \n",
       "\n",
       "          676       677       678       679       680       681       682  \n",
       "0    0.986131  0.957205  0.965213  0.974557  0.975362  0.959075  0.908659  \n",
       "1    0.945397  0.918154  0.970727  0.965741  0.968236  0.880703  0.840238  \n",
       "2    0.970533  0.779773  0.969907  0.924779  0.933613  0.893843  0.864202  \n",
       "3    0.975396  0.974159  0.989460  0.831055  0.815939  0.946884  0.901888  \n",
       "4    0.982619  0.976048  0.988140  0.951046  0.950153  0.935287  0.895721  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "678  0.986877  0.993546  0.000000  0.993665  0.993407  0.992462  0.985277  \n",
       "679  0.963013  0.975592  0.993665  0.000000  0.022451  0.891661  0.950135  \n",
       "680  0.962830  0.972397  0.993407  0.022451  0.000000  0.890135  0.945566  \n",
       "681  0.921980  0.641424  0.992462  0.891661  0.890135  0.000000  0.864907  \n",
       "682  0.916943  0.742582  0.985277  0.950135  0.945566  0.864907  0.000000  \n",
       "\n",
       "[683 rows x 683 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "distances = pd.DataFrame(pairwise_distances(X, metric=\"cosine\"))\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[10].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application : Faire un nuage de mots avec WordCloud\n",
    "\n",
    "Un coup d'oeil à la [documentation](https://amueller.github.io/word_cloud/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
