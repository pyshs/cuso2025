{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utiliser des modèles\n",
    "\n",
    "De plus en plus de modèles préentrainés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>display_name</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>language</th>\n",
       "      <th>type</th>\n",
       "      <th>type_crossref</th>\n",
       "      <th>...</th>\n",
       "      <th>locations.source</th>\n",
       "      <th>sustainable_development_goals.id</th>\n",
       "      <th>sustainable_development_goals.display_name</th>\n",
       "      <th>sustainable_development_goals.score</th>\n",
       "      <th>grants.funder</th>\n",
       "      <th>grants.funder_display_name</th>\n",
       "      <th>grants.award_id</th>\n",
       "      <th>counts_by_year.year</th>\n",
       "      <th>counts_by_year.cited_by_count</th>\n",
       "      <th>texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W2159397589</td>\n",
       "      <td>https://doi.org/10.1126/science.1167742</td>\n",
       "      <td>Computational Social Science</td>\n",
       "      <td>Computational Social Science</td>\n",
       "      <td>1318.19960</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009-02-06</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan|nan|nan|nan</td>\n",
       "      <td>https://metadata.un.org/sdg/10</td>\n",
       "      <td>Reduced inequalities</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023|2022|2021|2020|2019|2018|2017|2...</td>\n",
       "      <td>41|114|168|146|219|273|254|250|257|220|277|267...</td>\n",
       "      <td>Computational Social Science 14,0642,033Metric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W2070907364</td>\n",
       "      <td>https://doi.org/10.1140/epjst/e2012-01697-8</td>\n",
       "      <td>Manifesto of computational social science</td>\n",
       "      <td>Manifesto of computational social science</td>\n",
       "      <td>488.98035</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-11-01</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan|nan|nan|nan|nan|nan|nan|nan|nan|nan|nan</td>\n",
       "      <td>https://metadata.un.org/sdg/3</td>\n",
       "      <td>Good health and well-being</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023|2022|2021|2020|2019|2018|2017|2...</td>\n",
       "      <td>4|22|41|35|47|33|33|38|24|32|36|30|19|4</td>\n",
       "      <td>Manifesto of computational social science The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W3022499311</td>\n",
       "      <td>https://doi.org/10.1146/annurev-soc-121919-054621</td>\n",
       "      <td>Computational Social Science and Sociology</td>\n",
       "      <td>Computational Social Science and Sociology</td>\n",
       "      <td>365.42535</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan|nan</td>\n",
       "      <td>https://metadata.un.org/sdg/10</td>\n",
       "      <td>Reduced inequalities</td>\n",
       "      <td>0.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023|2022|2021|2020</td>\n",
       "      <td>17|51|65|56|34|9</td>\n",
       "      <td>Computational Social Science and Sociology The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://openalex.org/W4389636360</td>\n",
       "      <td>https://doi.org/10.1162/coli_a_00502</td>\n",
       "      <td>Can Large Language Models Transform Computatio...</td>\n",
       "      <td>Can Large Language Models Transform Computatio...</td>\n",
       "      <td>297.86798</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023</td>\n",
       "      <td>72|114|39</td>\n",
       "      <td>Can Large Language Models Transform Computatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://openalex.org/W3124521395</td>\n",
       "      <td>https://doi.org/10.3389/fpsyg.2014.00668</td>\n",
       "      <td>On agent-based modeling and computational soci...</td>\n",
       "      <td>On agent-based modeling and computational soci...</td>\n",
       "      <td>275.27340</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan|nan|nan|nan</td>\n",
       "      <td>https://metadata.un.org/sdg/10</td>\n",
       "      <td>Reduced inequalities</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023|2022|2021|2020|2019|2018|2017|2...</td>\n",
       "      <td>4|17|16|13|18|22|10|13|12|8|7|2|3</td>\n",
       "      <td>On agent-based modeling and computational soci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  https://openalex.org/W2159397589   \n",
       "1  https://openalex.org/W2070907364   \n",
       "3  https://openalex.org/W3022499311   \n",
       "7  https://openalex.org/W4389636360   \n",
       "9  https://openalex.org/W3124521395   \n",
       "\n",
       "                                                 doi  \\\n",
       "0            https://doi.org/10.1126/science.1167742   \n",
       "1        https://doi.org/10.1140/epjst/e2012-01697-8   \n",
       "3  https://doi.org/10.1146/annurev-soc-121919-054621   \n",
       "7               https://doi.org/10.1162/coli_a_00502   \n",
       "9           https://doi.org/10.3389/fpsyg.2014.00668   \n",
       "\n",
       "                                               title  \\\n",
       "0                       Computational Social Science   \n",
       "1          Manifesto of computational social science   \n",
       "3         Computational Social Science and Sociology   \n",
       "7  Can Large Language Models Transform Computatio...   \n",
       "9  On agent-based modeling and computational soci...   \n",
       "\n",
       "                                        display_name  relevance_score  \\\n",
       "0                       Computational Social Science       1318.19960   \n",
       "1          Manifesto of computational social science        488.98035   \n",
       "3         Computational Social Science and Sociology        365.42535   \n",
       "7  Can Large Language Models Transform Computatio...        297.86798   \n",
       "9  On agent-based modeling and computational soci...        275.27340   \n",
       "\n",
       "   publication_year publication_date language     type    type_crossref  ...  \\\n",
       "0              2009       2009-02-06       en  article  journal-article  ...   \n",
       "1              2012       2012-11-01       en  article  journal-article  ...   \n",
       "3              2020       2020-04-28       en  article  journal-article  ...   \n",
       "7              2023       2023-12-12       en  article  journal-article  ...   \n",
       "9              2014       2014-07-14       en  article  journal-article  ...   \n",
       "\n",
       "                                  locations.source  \\\n",
       "0                              nan|nan|nan|nan|nan   \n",
       "1  nan|nan|nan|nan|nan|nan|nan|nan|nan|nan|nan|nan   \n",
       "3                                      nan|nan|nan   \n",
       "7                                          nan|nan   \n",
       "9                              nan|nan|nan|nan|nan   \n",
       "\n",
       "   sustainable_development_goals.id  \\\n",
       "0    https://metadata.un.org/sdg/10   \n",
       "1     https://metadata.un.org/sdg/3   \n",
       "3    https://metadata.un.org/sdg/10   \n",
       "7                               NaN   \n",
       "9    https://metadata.un.org/sdg/10   \n",
       "\n",
       "   sustainable_development_goals.display_name  \\\n",
       "0                        Reduced inequalities   \n",
       "1                  Good health and well-being   \n",
       "3                        Reduced inequalities   \n",
       "7                                         NaN   \n",
       "9                        Reduced inequalities   \n",
       "\n",
       "  sustainable_development_goals.score grants.funder  \\\n",
       "0                                0.45           NaN   \n",
       "1                                0.47           NaN   \n",
       "3                                0.41           NaN   \n",
       "7                                 NaN           NaN   \n",
       "9                                0.47           NaN   \n",
       "\n",
       "   grants.funder_display_name  grants.award_id  \\\n",
       "0                         NaN              NaN   \n",
       "1                         NaN              NaN   \n",
       "3                         NaN              NaN   \n",
       "7                         NaN              NaN   \n",
       "9                         NaN              NaN   \n",
       "\n",
       "                                 counts_by_year.year  \\\n",
       "0  2025|2024|2023|2022|2021|2020|2019|2018|2017|2...   \n",
       "1  2025|2024|2023|2022|2021|2020|2019|2018|2017|2...   \n",
       "3                      2025|2024|2023|2022|2021|2020   \n",
       "7                                     2025|2024|2023   \n",
       "9  2025|2024|2023|2022|2021|2020|2019|2018|2017|2...   \n",
       "\n",
       "                       counts_by_year.cited_by_count  \\\n",
       "0  41|114|168|146|219|273|254|250|257|220|277|267...   \n",
       "1            4|22|41|35|47|33|33|38|24|32|36|30|19|4   \n",
       "3                                   17|51|65|56|34|9   \n",
       "7                                          72|114|39   \n",
       "9                  4|17|16|13|18|22|10|13|12|8|7|2|3   \n",
       "\n",
       "                                               texte  \n",
       "0  Computational Social Science 14,0642,033Metric...  \n",
       "1  Manifesto of computational social science The ...  \n",
       "3  Computational Social Science and Sociology The...  \n",
       "7  Can Large Language Models Transform Computatio...  \n",
       "9  On agent-based modeling and computational soci...  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/CSS_exact_openalex.csv\")\n",
    "df = df[~df[\"abstract\"].isna()]\n",
    "df[\"texte\"] = df[\"title\"] + \" \" + df[\"abstract\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Une approche intégrée avec SpaCy\n",
    "\n",
    "- `SpaCy` a des modèles entraînés pour les NER\n",
    "- Par exemple pour le français, [plusieurs modèles sont disponibles](https://spacy.io/models/fr)\n",
    "    - Avec des architectures différentes\n",
    "- Une bibliothèque qui donne un framework commun.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une étape : télécharger des modèles\n",
    "\n",
    "https://github.com/explosion/spacy-models/releases/tag/fr_core_news_md-3.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df.loc[3, \"texte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/IPython/core/display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m displacy\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdisplacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjupyter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/spacy/displacy/__init__.py:69\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(docs, style, page, minify, jupyter, options, manual)\u001b[39m\n\u001b[32m     65\u001b[39m     html = RENDER_WRAPPER(html)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jupyter \u001b[38;5;129;01mor\u001b[39;00m (jupyter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_in_jupyter()):\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# return HTML rendered by IPython display()\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# See #4840 for details on span wrapper to disable mathjax\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m display(HTML(\u001b[33m'\u001b[39m\u001b[33m<span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtex2jax_ignore\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m</span>\u001b[39m\u001b[33m'\u001b[39m.format(html)))\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/IPython/core/display.py)"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipuler les représentations du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational   | lemma: Computational | POS: PROPN\n",
      "Social          | lemma: Social | POS: PROPN\n",
      "Science         | lemma: Science | POS: PROPN\n",
      "and             | lemma: and | POS: CCONJ\n",
      "Sociology       | lemma: Sociology | POS: PROPN\n",
      "The             | lemma: the | POS: DET\n",
      "integration     | lemma: integration | POS: NOUN\n",
      "of              | lemma: of | POS: ADP\n",
      "social          | lemma: social | POS: ADJ\n",
      "science         | lemma: science | POS: NOUN\n",
      "with            | lemma: with | POS: ADP\n",
      "computer        | lemma: computer | POS: NOUN\n",
      "science         | lemma: science | POS: NOUN\n",
      "and             | lemma: and | POS: CCONJ\n",
      "engineering     | lemma: engineering | POS: NOUN\n",
      "fields          | lemma: field | POS: NOUN\n",
      "has             | lemma: have | POS: AUX\n",
      "produced        | lemma: produce | POS: VERB\n",
      "a               | lemma: a | POS: DET\n",
      "new             | lemma: new | POS: ADJ\n"
     ]
    }
   ],
   "source": [
    "for token in doc[0:20]:\n",
    "    print(f\"{token.text:<15} | lemma: {token.lemma_} | POS: {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADP'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[10].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational Social Science | label: ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents[0:10]:\n",
    "    print(f\"{ent.text:<25} | label: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc[0:100], style=\"dep\", jupyter=True, options={\"compact\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un usage : récupérer uniquement les verbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbs(doc):\n",
    "    \"\"\"\n",
    "    Get the verbs from a spacy doc\n",
    "    \"\"\"\n",
    "    return [token.lemma_ for token in doc if token.pos_ == \"VERB\"]\n",
    "\n",
    "tmp =  df[\"texte\"][0:100].apply(lambda x: get_verbs(nlp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', 82),\n",
       " ('base', 54),\n",
       " ('provide', 37),\n",
       " ('discuss', 34),\n",
       " ('make', 29),\n",
       " ('identify', 26),\n",
       " ('have', 26),\n",
       " ('understand', 23),\n",
       " ('include', 22),\n",
       " ('propose', 21),\n",
       " ('present', 21),\n",
       " ('generate', 21),\n",
       " ('develop', 20),\n",
       " ('show', 20),\n",
       " ('study', 19),\n",
       " ('offer', 19),\n",
       " ('explore', 19),\n",
       " ('increase', 18),\n",
       " ('address', 18),\n",
       " ('introduce', 17)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([j for i in tmp for j in i if j]).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un autre usage : nettoyer des textes\n",
    "\n",
    "Plutôt que faire de la tokenisation brutale, nettoyer en prenant uniquement les lemmes puis faire un TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aller utiliser d'autres modèles sur huggingface\n",
    "\n",
    "Commençons par faire un tour sur Huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire des entités nommées\n",
    "\n",
    "Utilsons le modèle [GliNER disponible sur HuggingFace](https://github.com/urchade/GLiNER)\n",
    "\n",
    "Ou sa version plus récente [GliNer](https://huggingface.co/knowledgator/gliner-multitask-large-v0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gliner\n",
      "  Downloading gliner-0.2.21-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting torch>=2.0.0 (from gliner)\n",
      "  Downloading torch-2.2.2-cp312-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting transformers>=4.38.2 (from gliner)\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting huggingface_hub>=0.21.4 (from gliner)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from gliner) (4.67.1)\n",
      "Collecting onnxruntime (from gliner)\n",
      "  Downloading onnxruntime-1.22.0-cp312-cp312-macosx_13_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting sentencepiece (from gliner)\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting filelock (from huggingface_hub>=0.21.4->gliner)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.21.4->gliner)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from huggingface_hub>=0.21.4->gliner) (25.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface_hub>=0.21.4->gliner)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from huggingface_hub>=0.21.4->gliner) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from huggingface_hub>=0.21.4->gliner) (4.14.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub>=0.21.4->gliner)\n",
      "  Downloading hf_xet-1.1.4-cp37-abi3-macosx_10_12_x86_64.whl.metadata (879 bytes)\n",
      "Collecting sympy (from torch>=2.0.0->gliner)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.0.0->gliner)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from torch>=2.0.0->gliner) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from transformers>=4.38.2->gliner) (2.3.0)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.38.2->gliner)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_10_13_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.38.2->gliner)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.38.2->gliner)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->gliner) (3.0.2)\n",
      "Collecting coloredlogs (from onnxruntime->gliner)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime->gliner)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime->gliner)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->gliner)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.4->gliner) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/spacy/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.4->gliner) (2025.6.15)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=2.0.0->gliner)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading gliner-0.2.21-py3-none-any.whl (65 kB)\n",
      "Downloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Downloading hf_xet-1.1.4-cp37-abi3-macosx_10_12_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-macosx_10_9_x86_64.whl (183 kB)\n",
      "Downloading torch-2.2.2-cp312-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-macosx_10_12_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-macosx_10_13_x86_64.whl (288 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl (436 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.0-cp312-cp312-macosx_13_0_universal2.whl (34.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: sentencepiece, mpmath, flatbuffers, sympy, safetensors, regex, pyyaml, protobuf, networkx, humanfriendly, hf-xet, fsspec, filelock, torch, huggingface_hub, coloredlogs, tokenizers, onnxruntime, transformers, gliner\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [gliner]18/20\u001b[0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.5.1 gliner-0.2.21 hf-xet-1.1.4 huggingface_hub-0.33.0 humanfriendly-10.0 mpmath-1.3.0 networkx-3.5 onnxruntime-1.22.0 protobuf-6.31.1 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 sentencepiece-0.2.0 sympy-1.14.0 tokenizers-0.21.1 torch-2.2.2 transformers-4.52.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3100, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3155, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3367, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3612, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3672, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/f9/d2d_05ws5gncmml0fx0c00kw0000gp/T/ipykernel_79203/1359053213.py\", line 1, in <module>\n",
      "    from gliner import GLiNER\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/gliner/__init__.py\", line 3, in <module>\n",
      "    from .model import GLiNER\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/gliner/model.py\", line 10, in <module>\n",
      "    import torch\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/spacy/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<00:00, 44243.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "# on récupère le modèle\n",
    "model = GLiNER.from_pretrained(\"knowledgator/gliner-multitask-large-v0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social media => software or algorithm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = df.loc[3, \"texte\"]\n",
    "\n",
    "labels = [\"software or algorithm\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De nombreux modèles et la possibilité d'en entraîner\n",
    "\n",
    "PAr exemple : https://huggingface.co/NousResearch/Minos-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de sentiment\n",
    "\n",
    "Une question : **quelles sont les prises de paroles les plus négatives ?**\n",
    "\n",
    "- Embarras du choix\n",
    "    - Par ex : [🚀 distilbert-based Multilingual Sentiment Classification Model\n",
    "](https://huggingface.co/tabularisai/multilingual-sentiment-analysis)\n",
    "- Comprendre le modèle / ce qu'il fait\n",
    "- Importance d'évaluer son résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser des modèles extérieurs\n",
    "\n",
    "Il faut un endpoint :\n",
    "\n",
    "- Ollama\n",
    "- OpenAI\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.3',\n",
       " 'created_at': '2025-05-20T15:57:20.053721724Z',\n",
       " 'response': 'NEGATIF',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'context': [128006,\n",
       "  882,\n",
       "  128007,\n",
       "  271,\n",
       "  14101,\n",
       "  54312,\n",
       "  1744,\n",
       "  3846,\n",
       "  69067,\n",
       "  1826,\n",
       "  20940,\n",
       "  333,\n",
       "  6033,\n",
       "  308,\n",
       "  19395,\n",
       "  50848,\n",
       "  551,\n",
       "  14465,\n",
       "  841,\n",
       "  60946,\n",
       "  82,\n",
       "  55455,\n",
       "  8065,\n",
       "  452,\n",
       "  12852,\n",
       "  13,\n",
       "  720,\n",
       "  8989,\n",
       "  75871,\n",
       "  82,\n",
       "  1744,\n",
       "  27592,\n",
       "  964,\n",
       "  2843,\n",
       "  6033,\n",
       "  85165,\n",
       "  835,\n",
       "  2843,\n",
       "  13,\n",
       "  128009,\n",
       "  128006,\n",
       "  78191,\n",
       "  128007,\n",
       "  271,\n",
       "  98227,\n",
       "  835,\n",
       "  2843],\n",
       " 'total_duration': 178492331,\n",
       " 'load_duration': 14576150,\n",
       " 'prompt_eval_count': 45,\n",
       " 'prompt_eval_duration': 44405857,\n",
       " 'eval_count': 4,\n",
       " 'eval_duration': 118533952}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# définir l'endpoint\n",
    "endpoint = \"\"\n",
    "\n",
    "# Définir la prompt de classification\n",
    "prompt = \"\"\"Est-ce que ce texte est positif ou négatif : Je ne comprends rien au NLP. \n",
    "Ne réponds que POSITIF ou NEGATIF.\"\"\"\n",
    "\n",
    "# Envoi de la requête à Ollama\n",
    "response = requests.post(\n",
    "    endpoint,\n",
    "    json={\n",
    "        'model': 'llama3.3',\n",
    "        'prompt': prompt,\n",
    "        'stream': False  # stream=False pour avoir une réponse simple\n",
    "    }\n",
    ")\n",
    "\n",
    "# Traitement de la réponse\n",
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
