{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utiliser des modèles\n",
    "\n",
    "De plus en plus de modèles préentrainés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>display_name</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>language</th>\n",
       "      <th>type</th>\n",
       "      <th>type_crossref</th>\n",
       "      <th>...</th>\n",
       "      <th>locations.source</th>\n",
       "      <th>sustainable_development_goals.id</th>\n",
       "      <th>sustainable_development_goals.display_name</th>\n",
       "      <th>sustainable_development_goals.score</th>\n",
       "      <th>grants.funder</th>\n",
       "      <th>grants.funder_display_name</th>\n",
       "      <th>grants.award_id</th>\n",
       "      <th>counts_by_year.year</th>\n",
       "      <th>counts_by_year.cited_by_count</th>\n",
       "      <th>texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W2159397589</td>\n",
       "      <td>https://doi.org/10.1126/science.1167742</td>\n",
       "      <td>Computational Social Science</td>\n",
       "      <td>Computational Social Science</td>\n",
       "      <td>1318.19960</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009-02-06</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan|nan|nan|nan</td>\n",
       "      <td>https://metadata.un.org/sdg/10</td>\n",
       "      <td>Reduced inequalities</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023|2022|2021|2020|2019|2018|2017|2...</td>\n",
       "      <td>41|114|168|146|219|273|254|250|257|220|277|267...</td>\n",
       "      <td>Computational Social Science 14,0642,033Metric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W2070907364</td>\n",
       "      <td>https://doi.org/10.1140/epjst/e2012-01697-8</td>\n",
       "      <td>Manifesto of computational social science</td>\n",
       "      <td>Manifesto of computational social science</td>\n",
       "      <td>488.98035</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-11-01</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan|nan|nan|nan|nan|nan|nan|nan|nan|nan|nan</td>\n",
       "      <td>https://metadata.un.org/sdg/3</td>\n",
       "      <td>Good health and well-being</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023|2022|2021|2020|2019|2018|2017|2...</td>\n",
       "      <td>4|22|41|35|47|33|33|38|24|32|36|30|19|4</td>\n",
       "      <td>Manifesto of computational social science The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W3022499311</td>\n",
       "      <td>https://doi.org/10.1146/annurev-soc-121919-054621</td>\n",
       "      <td>Computational Social Science and Sociology</td>\n",
       "      <td>Computational Social Science and Sociology</td>\n",
       "      <td>365.42535</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan|nan</td>\n",
       "      <td>https://metadata.un.org/sdg/10</td>\n",
       "      <td>Reduced inequalities</td>\n",
       "      <td>0.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023|2022|2021|2020</td>\n",
       "      <td>17|51|65|56|34|9</td>\n",
       "      <td>Computational Social Science and Sociology The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://openalex.org/W4389636360</td>\n",
       "      <td>https://doi.org/10.1162/coli_a_00502</td>\n",
       "      <td>Can Large Language Models Transform Computatio...</td>\n",
       "      <td>Can Large Language Models Transform Computatio...</td>\n",
       "      <td>297.86798</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023</td>\n",
       "      <td>72|114|39</td>\n",
       "      <td>Can Large Language Models Transform Computatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://openalex.org/W3124521395</td>\n",
       "      <td>https://doi.org/10.3389/fpsyg.2014.00668</td>\n",
       "      <td>On agent-based modeling and computational soci...</td>\n",
       "      <td>On agent-based modeling and computational soci...</td>\n",
       "      <td>275.27340</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>en</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>...</td>\n",
       "      <td>nan|nan|nan|nan|nan</td>\n",
       "      <td>https://metadata.un.org/sdg/10</td>\n",
       "      <td>Reduced inequalities</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025|2024|2023|2022|2021|2020|2019|2018|2017|2...</td>\n",
       "      <td>4|17|16|13|18|22|10|13|12|8|7|2|3</td>\n",
       "      <td>On agent-based modeling and computational soci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  https://openalex.org/W2159397589   \n",
       "1  https://openalex.org/W2070907364   \n",
       "3  https://openalex.org/W3022499311   \n",
       "7  https://openalex.org/W4389636360   \n",
       "9  https://openalex.org/W3124521395   \n",
       "\n",
       "                                                 doi  \\\n",
       "0            https://doi.org/10.1126/science.1167742   \n",
       "1        https://doi.org/10.1140/epjst/e2012-01697-8   \n",
       "3  https://doi.org/10.1146/annurev-soc-121919-054621   \n",
       "7               https://doi.org/10.1162/coli_a_00502   \n",
       "9           https://doi.org/10.3389/fpsyg.2014.00668   \n",
       "\n",
       "                                               title  \\\n",
       "0                       Computational Social Science   \n",
       "1          Manifesto of computational social science   \n",
       "3         Computational Social Science and Sociology   \n",
       "7  Can Large Language Models Transform Computatio...   \n",
       "9  On agent-based modeling and computational soci...   \n",
       "\n",
       "                                        display_name  relevance_score  \\\n",
       "0                       Computational Social Science       1318.19960   \n",
       "1          Manifesto of computational social science        488.98035   \n",
       "3         Computational Social Science and Sociology        365.42535   \n",
       "7  Can Large Language Models Transform Computatio...        297.86798   \n",
       "9  On agent-based modeling and computational soci...        275.27340   \n",
       "\n",
       "   publication_year publication_date language     type    type_crossref  ...  \\\n",
       "0              2009       2009-02-06       en  article  journal-article  ...   \n",
       "1              2012       2012-11-01       en  article  journal-article  ...   \n",
       "3              2020       2020-04-28       en  article  journal-article  ...   \n",
       "7              2023       2023-12-12       en  article  journal-article  ...   \n",
       "9              2014       2014-07-14       en  article  journal-article  ...   \n",
       "\n",
       "                                  locations.source  \\\n",
       "0                              nan|nan|nan|nan|nan   \n",
       "1  nan|nan|nan|nan|nan|nan|nan|nan|nan|nan|nan|nan   \n",
       "3                                      nan|nan|nan   \n",
       "7                                          nan|nan   \n",
       "9                              nan|nan|nan|nan|nan   \n",
       "\n",
       "   sustainable_development_goals.id  \\\n",
       "0    https://metadata.un.org/sdg/10   \n",
       "1     https://metadata.un.org/sdg/3   \n",
       "3    https://metadata.un.org/sdg/10   \n",
       "7                               NaN   \n",
       "9    https://metadata.un.org/sdg/10   \n",
       "\n",
       "   sustainable_development_goals.display_name  \\\n",
       "0                        Reduced inequalities   \n",
       "1                  Good health and well-being   \n",
       "3                        Reduced inequalities   \n",
       "7                                         NaN   \n",
       "9                        Reduced inequalities   \n",
       "\n",
       "  sustainable_development_goals.score grants.funder  \\\n",
       "0                                0.45           NaN   \n",
       "1                                0.47           NaN   \n",
       "3                                0.41           NaN   \n",
       "7                                 NaN           NaN   \n",
       "9                                0.47           NaN   \n",
       "\n",
       "   grants.funder_display_name  grants.award_id  \\\n",
       "0                         NaN              NaN   \n",
       "1                         NaN              NaN   \n",
       "3                         NaN              NaN   \n",
       "7                         NaN              NaN   \n",
       "9                         NaN              NaN   \n",
       "\n",
       "                                 counts_by_year.year  \\\n",
       "0  2025|2024|2023|2022|2021|2020|2019|2018|2017|2...   \n",
       "1  2025|2024|2023|2022|2021|2020|2019|2018|2017|2...   \n",
       "3                      2025|2024|2023|2022|2021|2020   \n",
       "7                                     2025|2024|2023   \n",
       "9  2025|2024|2023|2022|2021|2020|2019|2018|2017|2...   \n",
       "\n",
       "                       counts_by_year.cited_by_count  \\\n",
       "0  41|114|168|146|219|273|254|250|257|220|277|267...   \n",
       "1            4|22|41|35|47|33|33|38|24|32|36|30|19|4   \n",
       "3                                   17|51|65|56|34|9   \n",
       "7                                          72|114|39   \n",
       "9                  4|17|16|13|18|22|10|13|12|8|7|2|3   \n",
       "\n",
       "                                               texte  \n",
       "0  Computational Social Science 14,0642,033Metric...  \n",
       "1  Manifesto of computational social science The ...  \n",
       "3  Computational Social Science and Sociology The...  \n",
       "7  Can Large Language Models Transform Computatio...  \n",
       "9  On agent-based modeling and computational soci...  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/CSS_exact_openalex.csv\")\n",
    "df = df[~df[\"abstract\"].isna()]\n",
    "df[\"texte\"] = df[\"title\"] + \" \" + df[\"abstract\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Une approche intégrée avec SpaCy\n",
    "\n",
    "- `SpaCy` a des modèles entraînés pour les NER\n",
    "- Par exemple pour le français, [plusieurs modèles sont disponibles](https://spacy.io/models/fr)\n",
    "    - Avec des architectures différentes\n",
    "- Une bibliothèque qui donne un framework commun.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une étape : télécharger des modèles\n",
    "\n",
    "https://github.com/explosion/spacy-models/releases/tag/fr_core_news_md-3.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df.loc[3, \"texte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spacy import displacy\n",
    "#displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipuler les représentations du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational   | lemma: Computational | POS: PROPN\n",
      "Social          | lemma: Social | POS: PROPN\n",
      "Science         | lemma: Science | POS: PROPN\n",
      "and             | lemma: and | POS: CCONJ\n",
      "Sociology       | lemma: Sociology | POS: PROPN\n",
      "The             | lemma: the | POS: DET\n",
      "integration     | lemma: integration | POS: NOUN\n",
      "of              | lemma: of | POS: ADP\n",
      "social          | lemma: social | POS: ADJ\n",
      "science         | lemma: science | POS: NOUN\n",
      "with            | lemma: with | POS: ADP\n",
      "computer        | lemma: computer | POS: NOUN\n",
      "science         | lemma: science | POS: NOUN\n",
      "and             | lemma: and | POS: CCONJ\n",
      "engineering     | lemma: engineering | POS: NOUN\n",
      "fields          | lemma: field | POS: NOUN\n",
      "has             | lemma: have | POS: AUX\n",
      "produced        | lemma: produce | POS: VERB\n",
      "a               | lemma: a | POS: DET\n",
      "new             | lemma: new | POS: ADJ\n"
     ]
    }
   ],
   "source": [
    "for token in doc[0:20]:\n",
    "    print(f\"{token.text:<15} | lemma: {token.lemma_} | POS: {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[12].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[integration,\n",
       " science,\n",
       " computer,\n",
       " science,\n",
       " engineering,\n",
       " fields,\n",
       " area,\n",
       " study,\n",
       " science,\n",
       " field,\n",
       " methods,\n",
       " sources,\n",
       " data,\n",
       " media,\n",
       " records,\n",
       " archives,\n",
       " theories,\n",
       " behavior,\n",
       " evolution,\n",
       " field,\n",
       " sociology,\n",
       " analysis,\n",
       " depth,\n",
       " analysis,\n",
       " subfields,\n",
       " work]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in doc if token.pos_==\"NOUN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero                      | label: CARDINAL\n",
      "zero                      | label: CARDINAL\n",
      "zero                      | label: CARDINAL\n",
      "13                        | label: CARDINAL\n",
      "25                        | label: CARDINAL\n",
      "English                   | label: LANGUAGE\n",
      "today                     | label: DATE\n",
      "CSS                       | label: ORG\n",
      "two                       | label: CARDINAL\n",
      "1                         | label: CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for ent in  nlp(df.loc[7, \"texte\"]).ents[0:10]:\n",
    "    print(f\"{ent.text:<25} | label: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc[0:100], style=\"dep\", jupyter=True, options={\"compact\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un usage : récupérer uniquement les verbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbs(doc):\n",
    "    \"\"\"\n",
    "    Get the verbs from a spacy doc\n",
    "    \"\"\"\n",
    "    return [token.lemma_ for token in doc if token.pos_ == \"VERB\"]\n",
    "\n",
    "tmp =  df[\"texte\"][0:100].apply(lambda x: get_verbs(nlp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', 82),\n",
       " ('base', 54),\n",
       " ('provide', 37),\n",
       " ('discuss', 34),\n",
       " ('make', 29),\n",
       " ('identify', 26),\n",
       " ('have', 26),\n",
       " ('understand', 23),\n",
       " ('include', 22),\n",
       " ('propose', 21),\n",
       " ('present', 21),\n",
       " ('generate', 21),\n",
       " ('develop', 20),\n",
       " ('show', 20),\n",
       " ('study', 19),\n",
       " ('offer', 19),\n",
       " ('explore', 19),\n",
       " ('increase', 18),\n",
       " ('address', 18),\n",
       " ('introduce', 17)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([j for i in tmp for j in i if j]).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un autre usage : nettoyer des textes\n",
    "\n",
    "Plutôt que faire de la tokenisation brutale, nettoyer en prenant uniquement les lemmes puis faire un TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aller utiliser d'autres modèles sur huggingface\n",
    "\n",
    "Commençons par faire un tour sur Huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire des entités nommées\n",
    "\n",
    "Utilsons le modèle [GliNER disponible sur HuggingFace](https://github.com/urchade/GLiNER)\n",
    "\n",
    "Ou sa version plus récente [GliNer](https://huggingface.co/knowledgator/gliner-multitask-large-v0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995e1c1b77f347b6b76dfab0caa2faa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "# on récupère le modèle\n",
    "model = GLiNER.from_pretrained(\"knowledgator/gliner-multitask-large-v0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cognitive models => software or algorithm\n"
     ]
    }
   ],
   "source": [
    "text = df.loc[9, \"texte\"]\n",
    "labels = [\"software or algorithm\",\"countries\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De nombreux modèles et la possibilité d'en entraîner\n",
    "\n",
    "PAr exemple : https://huggingface.co/NousResearch/Minos-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de sentiment\n",
    "\n",
    "Une question : **quelles sont les prises de paroles les plus négatives ?**\n",
    "\n",
    "- Embarras du choix\n",
    "    - Par ex : [🚀 distilbert-based Multilingual Sentiment Classification Model\n",
    "](https://huggingface.co/tabularisai/multilingual-sentiment-analysis)\n",
    "- Comprendre le modèle / ce qu'il fait\n",
    "- Importance d'évaluer son résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser des modèles extérieurs\n",
    "\n",
    "Il faut un endpoint :\n",
    "\n",
    "- Ollama\n",
    "- OpenAI\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.3',\n",
       " 'created_at': '2025-05-20T15:57:20.053721724Z',\n",
       " 'response': 'NEGATIF',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'context': [128006,\n",
       "  882,\n",
       "  128007,\n",
       "  271,\n",
       "  14101,\n",
       "  54312,\n",
       "  1744,\n",
       "  3846,\n",
       "  69067,\n",
       "  1826,\n",
       "  20940,\n",
       "  333,\n",
       "  6033,\n",
       "  308,\n",
       "  19395,\n",
       "  50848,\n",
       "  551,\n",
       "  14465,\n",
       "  841,\n",
       "  60946,\n",
       "  82,\n",
       "  55455,\n",
       "  8065,\n",
       "  452,\n",
       "  12852,\n",
       "  13,\n",
       "  720,\n",
       "  8989,\n",
       "  75871,\n",
       "  82,\n",
       "  1744,\n",
       "  27592,\n",
       "  964,\n",
       "  2843,\n",
       "  6033,\n",
       "  85165,\n",
       "  835,\n",
       "  2843,\n",
       "  13,\n",
       "  128009,\n",
       "  128006,\n",
       "  78191,\n",
       "  128007,\n",
       "  271,\n",
       "  98227,\n",
       "  835,\n",
       "  2843],\n",
       " 'total_duration': 178492331,\n",
       " 'load_duration': 14576150,\n",
       " 'prompt_eval_count': 45,\n",
       " 'prompt_eval_duration': 44405857,\n",
       " 'eval_count': 4,\n",
       " 'eval_duration': 118533952}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# définir l'endpoint\n",
    "endpoint = \"\"\n",
    "\n",
    "# Définir la prompt de classification\n",
    "prompt = \"\"\"Est-ce que ce texte est positif ou négatif : Je ne comprends rien au NLP. \n",
    "Ne réponds que POSITIF ou NEGATIF.\"\"\"\n",
    "\n",
    "# Envoi de la requête à Ollama\n",
    "response = requests.post(\n",
    "    endpoint,\n",
    "    json={\n",
    "        'model': 'llama3.3',\n",
    "        'prompt': prompt,\n",
    "        'stream': False  # stream=False pour avoir une réponse simple\n",
    "    }\n",
    ")\n",
    "\n",
    "# Traitement de la réponse\n",
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
